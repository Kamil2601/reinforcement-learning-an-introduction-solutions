{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.4\n",
    "\n",
    "| $s$             | $a$                 | $s'$            | $r$          | $p(s', r \\| s, a)$|\n",
    "| ----            | ----                | ----            | ---          | ----------------- |\n",
    "| $\\texttt{high}$ | $\\texttt{search}$   | $\\texttt{high}$ | $r_{search}$ | $\\alpha$          |\n",
    "| $\\texttt{high}$ | $\\texttt{search}$   | $\\texttt{low}$  | $r_{search}$ | $1-\\alpha$        |\n",
    "| $\\texttt{high}$ | $\\texttt{wait}$     | $\\texttt{high}$ | $r_{wait}$   | 1                 |\n",
    "| $\\texttt{low}$  | $\\texttt{search}$   | $\\texttt{high}$ | $-3$         | $1-\\beta$         |\n",
    "| $\\texttt{low}$  | $\\texttt{search}$   | $\\texttt{low}$  | $r_{search}$ | $\\beta$           |\n",
    "| $\\texttt{low}$  | $\\texttt{wait}$     | $\\texttt{low}$  | $r_{wait}$   | 1                 |\n",
    "| $\\texttt{low}$  | $\\texttt{recharge}$ | $\\texttt{high}$ | 0            |  1                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.8\n",
    "If we use as a return, a sum of rewards without discount\n",
    "$$\n",
    "G_t = R_{t+1} + R_{t+2} + \\cdots + R_T\n",
    "$$\n",
    "then the return of the episode is always 1, no matter how long is the episode, so the agent doesn't learn how to find a shorter way through the maze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.10\n",
    "Sum of first n elements of geometric sequence, where $a_{n+1} = qa_n$\n",
    "$$\n",
    "S_n = a_1\\frac{1-q^n}{1-q}\n",
    "$$\n",
    "In our case $a_1 = 0$ and $q=\\gamma$, so\n",
    "$$\n",
    "S_n = \\frac{1-\\gamma^n}{1-\\gamma}\n",
    "$$\n",
    "$$\n",
    "S_{\\infty} = lim_{n \\to \\infty} \\frac{1-\\gamma^n}{1-\\gamma} = \\frac{1}{1-\\gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.11\n",
    "$$\n",
    "E[R_{t+1} | S_t = s] = \\sum_{a \\in \\mathcal{A}} \\pi(a | s) \\sum_{r \\in \\mathcal{R}, s' \\in \\mathcal{S}} p(s', r | s, a) * r\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.12\n",
    "$$\n",
    "v_{\\pi}(s) = \\sum_{a \\in \\mathcal{A}} \\pi(a | s) * q_{\\pi}(s, a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.13\n",
    "$$\n",
    "q_{\\pi}(s,a) = \\sum_{r \\in \\mathcal{R}, s' \\in \\mathcal{S}} p(s', r | s, a) * [r + \\gamma v_{\\pi}(s')]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.14\n",
    "$$\n",
    "v_\\pi(s) = \\sum_a \\pi(a|s)\\sum_{s',r} p(s', r | s, a) [r + \\gamma v_\\pi(s')]\n",
    "$$\n",
    "\n",
    "In our case:\n",
    "$$v_\\pi(s) = 0.7$$\n",
    "$$\n",
    "v_\\pi(s') = \\{2.3; 0.4; -0.4; 0.7\\} \\text{ for each } s'\n",
    "$$\n",
    "$$\n",
    "r = 0 \\text{ always}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\gamma = 0.9\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi(a | s) = 0.25 \\text{ for all } a\n",
    "$$\n",
    "\n",
    "So\n",
    "$$\n",
    "v_\\pi(s) = 0.25 * 1 * 0.9 * (2.3 + 0.4 - 0.4 + 0.7) = 0.25 * 0.9 * 3 = 0.675 \\approx 0.7\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.15\n",
    "$$\n",
    "G_t = \\sum_{k=0}^{\\infty}\\gamma^k R_{t+k+1}\n",
    "$$\n",
    "$$\n",
    "v_\\pi(s) = E[G_t | S_t = s]\n",
    "$$\n",
    "\n",
    "When we add constant $c$ to all rewards then we get new return $G_t'$\n",
    "$$\n",
    "G_t' = \\sum_{k=0}^\\infty \\gamma^k (R_{t+k+1} + c) = \\sum_{k=0}^\\infty \\gamma^k R_{t+k+1} + \\sum_{k=0}^\\infty \\gamma^k c = G_t + c\\sum_{k=0}^\\infty \\gamma^k = G_t + \\frac{c}{1-\\gamma}\n",
    "$$\n",
    "So\n",
    "$$\n",
    "v_c = \\frac{c}{1-\\gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3.16\n",
    "For episodic tasks we have\n",
    "$$\n",
    "G_t = \\sum_{k=0}^{l}\\gamma^k R_{t+k+1}\n",
    "$$\n",
    "where $l$ is the length of the episode, so\n",
    "$$\n",
    "G_t' =  \\sum_{k=0}^{l}\\gamma^k (R_{t+k+1} + c) = G_t + c \\sum_{k=0}^{l}\\gamma^k = G_t + c\\frac{1-\\gamma^l}{1-\\gamma}\n",
    "$$,\n",
    "so $v_c$ isn't constant, it depends on the length of the episode $l$\n",
    "$$\n",
    "v_c = c\\frac{1-\\gamma^l}{1-\\gamma}\n",
    "$$\n",
    "\n",
    "It can change relative values of states. Example problem:\n",
    "* states $s_1$, $s_2$ (there are more states in the environment) both have exactly one possible episode ($v_\\pi(s) = G_t$) of lengths 1 and 2 respectively,\n",
    "* $\\gamma = 0.5$\n",
    "* $v_{\\pi}(s_1) - v_\\pi(s_2) = 0.25c$\n",
    "\n",
    "So we have\n",
    "$$\n",
    "v_{\\pi}'(s_1) - v_\\pi'(s_2) = (v_{\\pi}(s_1) + c\\frac{1-0.5^1}{1-0.5}) - (v_{\\pi}(s_2) + c\\frac{1-0.5^2}{1-0.5}) = (v_{\\pi}(s_1) - v_{\\pi}(s_2)) + (c - 1.5c) = 0.25c - 0.5c = -0.25c\n",
    "$$\n",
    "so $v_{\\pi}(s_1) > v_\\pi(s_2)$ and $v_{\\pi}'(s_1) < v_\\pi'(s_2)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
