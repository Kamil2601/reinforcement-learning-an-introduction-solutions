{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1\n",
    "\n",
    "\n",
    "1. $\\delta_t = R_{t+1} + \\gamma V_t(S_{t+1}) - V_t(S_t)$\n",
    "2. $V_{t+1}(S_t) = V_t(S_t) + \\alpha [R_{t+1} + \\gamma V_t(S_{t+1}) - V_t(S_t)]$\n",
    "3. $V_{k+1}(S_t) = V_k(S_t) + \\alpha [R_{t+2} + \\gamma V_k(S_{t+1}) - V_k(S_t)]$ (generalized 2)\n",
    "\n",
    "$\n",
    "G_t - V_t(S_t) \\\\\n",
    "= R_{t+1} + \\gamma G_{t+1} - V_t(S) \\\\\n",
    "= R_{t+1} + \\gamma V_t(S_{t+1}) - V_t(S_t) + \\gamma G_{t+1} - \\gamma V_t(S_{t+1}) \\\\\n",
    "= \\delta_t + \\gamma G_{t+1} - \\gamma V_t(S_{t+1}) \\\\\n",
    "= \\delta_t + \\gamma [G_{t+1} - V_{t+1}(S_{t+1})] + \\gamma [V_{t+1}(S_{t+1}) - V_t(S_{t+1})]\n",
    "= \\delta_t + \\gamma [G_{t+1} - V_{t+1}(S_{t+1})] + \\gamma [V_t(S_{t+1}) + \\alpha [R_{t+2} + \\gamma V_t(S_{t+2}) - V_t{S_{t+2}}] - V_t(S_{t+1})] \\text{   (from 3.)} \\\\\n",
    "= \\delta_t + \\gamma [G_{t+1} - V_{t+1}(S_{t+1})] + \\alpha \\gamma [R_{t+2} + \\gamma V_t(S_{t+2}) - V_t{S_{t+2}}] \\\\\n",
    "\\text{Now } [G_{t+1} - V_{t+1}(S_{t+1})] \\text{ is the first formula with higher index, so we have recursive unfolding} \\\\\n",
    "= \\delta_t + \\gamma [\\delta_{t+1} + \\gamma[G_{t+2} - V_{t+2}(S_{t+2})] + \\alpha \\gamma [R_{t+3} + \\gamma V_{t+1}(S_{t+3}) - V_{t+1}(S_{t+2})]] + \\alpha \\gamma [R_{t+2} + \\gamma V_t(S_{t+2}) - V_t{S_{t+2}}] \\\\\n",
    "= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2[G_{t+2} - V_{t+2}(S_{t+2})] + \\alpha [\\gamma^2 [R_{t+3} + \\gamma V_{t+1}(S_{t+3}) - V_{t+1}(S_{t+2})] + \\gamma [R_{t+2} + \\gamma V_t(S_{t+2}) - V_t{S_{t+2}}]] \\\\\n",
    "... \\\\\n",
    "= \\sum_{k=t}^{T-1} \\gamma^{k-t} \\delta_k + \\alpha \\sum_{k=t}^{T-2} \\gamma^{k-t+1} [R_{k+2} + \\gamma V_k(S_{k+2}) - V_k(S_{k+1})]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "**Hereâ€™s a hint**: Suppose you have lots of experience driving home from work. Then you move to a new building and a new parking lot (but you still enter the highway at the same place). Now you are starting to learn predictions for the new building.\n",
    "\n",
    "Suppose that the old route home is described by trajectory $\\tau_{old} = S_1S_2...S_n$, and the new route by trajectory $tau_{new}=S_1'S_2...S_n$. We have good estimate for $\\tau_{old}$ and for all its states, now we want to estimate $\\tau_{new}$. In case of Monte Carlo, each update of $V_(S_1')$ will only use the single episode. In case of TD learning, each update will use the old estimates of $S_2, S_3, ..., S_n$, which are much more accurate than a single episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Since, only the $V(A)$ changed in the first episode, the first episode has to be: $C,0,B,0,A,0$.\n",
    "\n",
    "Then, in the estimation we update $V(C)$, $V(B)$, $V(A)$ in this order. For $V(C)$ we have:\n",
    "$$\n",
    "V(C) \\leftarrow V(C) + \\alpha [R + \\gamma V(B) - V(C)]\n",
    "$$\n",
    "We know that $V(S) = 0.5$ for all $S$, $R = 0$, $\\alpha = 0.1$ and $\\gamma = 1$, so\n",
    "\n",
    "$$\n",
    "V(C) \\leftarrow V(C) + 0.1 \\cdot [0 + 0.5 - 0.5] \n",
    "$$\n",
    "$$\n",
    "V(C) \\leftarrow V(C)\n",
    "$$\n",
    "So $V(C)$ doesnt change, the same for $V(B)$. For $V(A)$ we have\n",
    "$$\n",
    "V(A) \\leftarrow V(A) + \\alpha [R + \\gamma V(terminal) - V(A)]\n",
    "$$\n",
    "$V(terminal) = 0$, so\n",
    "$$\n",
    "V(A) \\leftarrow 0.5 + 0.1 \\cdot [0 + 0 - 0.5]\n",
    "$$\n",
    "$$\n",
    "V(A) \\leftarrow 0.45\n",
    "$$\n",
    "\n",
    "So $V(A)$ changed from 0.5 to 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.4\n",
    "No, the wider range of the step-size parameter $\\alpha$ wouldn't affect the conclusions about which algorithm is better.\n",
    "\n",
    "#### Explanation\n",
    "First, let's look at the error of TD. $\\alpha = 0.05$ achieved the best result - error below $0.05$, error curve becomes flat around episode 75. Lower values of $\\alpha$ would probably reach the same error (or maybe a little smaller) but in more steps.\n",
    "\n",
    "Higher values of $\\alpha$ converged faster during the first 25-50 steps, but later they started to get worse, the error went up. This effect (faster convergence at the beggining and divergence soon) is bigger for $\\alpha = 0.15$ than for $\\alpha = 0.1$ so it would have been even bigger for larger $\\alpha$.\n",
    "\n",
    "Now let's look at MC. For the lowest $\\alpha = 0.01$, the error curve is the most smooth, but the learning is very slow, the error after 100 episodes is significantly higher than for TD (around 0.12). For higher values of $\\alpha$ the algorithm converges faster, after around 50 episodes we can see that the error often goes up in the next steps, more often and higher for larger $\\alpha$, this effect would be greater for larger $\\alpha$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6,5*\n",
    "We initialize estimate values $V(S) = 0.5$ for each state $S$, so each estimate except for $V(C)$ is quite far from the true value of the state. At the beginning, with each update, each of these estimates changes toward the true value of the state. The problem starts to occur when the estimates are close to the true values, then the update can move it away from the true value, resulting in higher error.\n",
    "\n",
    "For example, let's assume that estimates for $A$, $B$ $C$ are equal to the true values: $V(A) = \\frac{1}{6}$, $V(B) = \\frac{2}{6}$, $V(C) = \\frac{3}{6}$, and the next episode is $C,0,B,0,A,0$. Then we have the following updates for $V(C), $V(B)$ and $V(A)$\n",
    "\n",
    "* $V(C) \\leftarrow V(C) + \\alpha [0 + V(B) - V(C)] = \\frac{3}{6} + \\alpha [0 + \\frac{2}{6} - \\frac{3}{6}] = \\frac{3}{6} - \\alpha \\frac{1}{6}$\n",
    "* $V(B) \\leftarrow V(B) + \\alpha [0 + V(A) - V(B)] = \\frac{2}{6} + \\alpha [0 + \\frac{1}{6} - \\frac{2}{6}] = \\frac{2}{6} - \\alpha \\frac{1}{6}$\n",
    "* $V(A) \\leftarrow V(A) + \\alpha [0 + V(terminal) - V(A)] = \\frac{2}{6} + \\alpha [0 + 0 - \\frac{1}{6}] = \\frac{1}{6} - \\alpha \\frac{1}{6}$\n",
    "\n",
    "Each estimated value after update is further away from the true value than before update, so the mean square error will be higher after this step. The difference is greater for greater $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.6\n",
    "\n",
    "The true values of states can be found by solving the following system of equations.\n",
    "\n",
    "$V(A) = 0.5 \\cdot 0 + 0.5 \\cdot V(B)\\\\$\n",
    "$V(B) = 0.5 \\cdot V(B) + 0.5 \\cdot V(C)\\\\$\n",
    "$V(C) = 0.5 \\cdot V(B) + 0.5 \\cdot V(D)\\\\$\n",
    "$V(D) = 0.5 \\cdot V(C) + 0.5 \\cdot V(E)\\\\$\n",
    "$V(E) = 0.5 \\cdot V(D) + 0.5 \\cdot 1\\\\$\n",
    "\n",
    "Which can be solved either\n",
    "1. analytically, or\n",
    "2. using dynamic programming.\n",
    "\n",
    "I think that, the analitical solutions was used, since this system is fairly easy to solve. It would probably require less calculations than using dynamic programming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.7*\n",
    "\n",
    "$$\n",
    "V(S_t) \\leftarrow V(S_t) + \\alpha \\rho_{t:t} [R_{t+1} + \\gamma V(S_{t+1}) - V(S_t)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.8\n",
    "$\\delta_t = R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t)$\n",
    "\n",
    "\\begin{split}\n",
    "G_t - Q(S_t, A_t) &= R_{t+1} + \\gamma G_{t+1} - Q(S_t, A_t) + \\gamma Q(S_{t+1}, A_{t+1}) - \\gamma Q(S_{t+1}, A_{t+1})\\\\\n",
    "                  &= \\delta_t + \\gamma (G_{t+1} - Q(S_{t+1}, A_{t+1}))\\\\\n",
    "                  &= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2(G_{t+2} - Q(S_{t+2}, A_{t+2}))\\\\\n",
    "                  &= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2\\gamma \\delta_{t+2} + ... + \\gamma^{T-t-1}\\delta_{T-1} + \\gamma^{T-1}(G_T - Q(S_T, \\cdot))\\\\\n",
    "                  &= \\delta_t + \\gamma \\delta_{t+1} + \\gamma^2\\gamma \\delta_{t+2} + ... + \\gamma^{T-t-1}\\delta_{T-1} + \\gamma^{T-1}(0 - 0)\\\\\n",
    "                  &= \\sum_{k=t}^{T-1}\\gamma^{k-t}\\delta_k\n",
    "\\end{split}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
